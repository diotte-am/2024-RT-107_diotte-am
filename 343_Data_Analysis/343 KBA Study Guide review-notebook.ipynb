{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an overview review for the 341, 342, 343 KBA that will be next week.  \n",
    "This is pretty comprehensive and you should do well if you practice these concepts on a few data sources.  \n",
    "\n",
    "2024.05.22 vlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Environments in Main Purpose: To create an isolated environment for each project.\n",
    "\n",
    "Detailed Explanation:\n",
    "To create an isolated environment for each project: This is the primary reason for using virtual environments. It allows each project to have its own dependencies, libraries, and versions of those libraries, without interfering with other projects. This isolation helps in avoiding conflicts between different projects' dependencies.\n",
    "\n",
    "Virtual environments do not affect the time complexity of your code.\n",
    "\n",
    "Virtual environments themselves do not inherently reduce memory usage. However, they can help manage dependencies more efficiently.\n",
    "\n",
    "To use different versions of Python for each project: This is true and a significant advantage, but it is not the PRIMARY advantage. You can have different projects running on different versions of Python.\n",
    "\n",
    "Virtual environments do not make Python projects platform independent. They help manage dependencies within the same platform.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Functions\n",
    "Lambda functions in Python are designed to contain a single expression. You **cannot** use semicolons to separate multiple expressions.\n",
    "\n",
    "A colon, \":\", must be used to define a lambda function. The syntax for a lambda function is **lambda arguments: expression**\n",
    "\n",
    "A lambda function can take zero or more arguments. For example, lambda: 42 is a valid lambda function that takes no arguments.\n",
    "\n",
    "Lambda functions are often used as anonymous functions, meaning they are defined at the point where they are needed, without giving them a name. A lambda function can be defined on the fly without specifying its name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and SciPy\n",
    "Numeric Python and Scientific SciPy is built on the NumPy extension of Python.\n",
    "Although there are some overlaps between them, SciPy provides more tools for complex computing of numerical data. Although there are some overlaps between them, SciPy provides more tools for complex computing of numerical data such as optimization, integration, interpolation, eigenvalue problems, and other advanced mathematical functions.\n",
    "\n",
    "NumPy is a standalone package that provides support for arrays and matrices, along with a collection of mathematical functions to operate on these data structures. SciPy builds on NumPy but NumPy is **NOT** a part of SciPy!\n",
    "\n",
    "Both provide an array type but a NumPy array is faster than a SciPy array: This statement is not accurate. Both NumPy and SciPy use the same array type provided by NumPy. There is no separate SciPy array type, therefore they run at the same speed (that of the underlying NumPy array processing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Features of Pandas from data manipulation and analysis library in \n",
    "Pandas provides a comprehensive set of tools for working with structured data, making it an essential library for data analysis and manipulation in Python.\n",
    "## Practical Applications\n",
    "Data Cleaning and Preparation: Preparing raw data for analysis by **handling missing values**, **filtering data**, and **merging datasets.**\n",
    "Data Analysis: Performing exploratory data analysis (EDA) to understand the data's structure, trends, and patterns.\n",
    "Data Science and Machine Learning: Preparing datasets for machine learning models, including feature engineering and selection.\n",
    "\n",
    "## Data Structures:\n",
    "\n",
    "Series: A one-dimensional labeled array capable of holding any data type.\n",
    "DataFrame: A two-dimensional labeled data structure with columns that can be of different data types (similar to a table or a spreadsheet).\n",
    "Data Alignment and Handling Missing Data:\n",
    "\n",
    "Automatic Data Alignment: Aligns data in Series and DataFrame objects based on labels, which makes operations with different indices easy.\n",
    "Handling Missing Data: Provides tools for detecting, filling, and dropping missing values using functions like isna(), fillna(), and dropna().\n",
    "## Data Input and Output:\n",
    "\n",
    "Reading Data: Functions to read data from various file formats such as CSV (read_csv()), Excel (read_excel()), SQL databases (read_sql()), JSON (read_json()), and more.\n",
    "Writing Data: Functions to write data to various file formats such as CSV (to_csv()), Excel (to_excel()), SQL databases (to_sql()), JSON (to_json()), and more.\n",
    "## Data Manipulation:\n",
    "\n",
    "Selection and Filtering: Methods for selecting and filtering data, such as .loc[], .iloc[], .at[], and .iat[].\n",
    "Aggregation and Grouping: Tools for grouping data and performing aggregations, like groupby(), agg(), and pivot_table().\n",
    "Merging and Joining: Functions for merging, joining, and concatenating datasets, such as merge(), join(), and concat().\n",
    "## Data Cleaning and Preparation:\n",
    "String Manipulation: Functions for manipulating string data using .str accessor.\n",
    "Handling Duplicates: Methods to find and remove duplicate data using duplicated() and drop_duplicates().\n",
    "## Data Analysis and Exploration:\n",
    "Descriptive Statistics: Functions to compute basic descriptive statistics, such as mean(), median(), sum(), min(), max(), std(), and describe().\n",
    "Correlation and Covariance: Methods to compute correlation and covariance between different columns using corr() and cov().\n",
    "## Time Series Analysis:\n",
    "Datetime Support: Tools for handling and manipulating datetime data, like to_datetime(), date_range(), and .dt accessor.\n",
    "Resampling and Frequency Conversion: Functions for resampling time series data, such as resample() and asfreq().\n",
    "\n",
    "## Performance and Optimization:\n",
    "Vectorized Operations: Efficient operations on data without the need for explicit loops, leading to faster performance.\n",
    "Memory Usage: Tools for managing and reducing memory usage, such as astype() for changing data types.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame creation in Pandas involves using the pd.DataFrame() function from the Pandas library. Below are some common methods to create a DataFrame:\n",
    "\n",
    "pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "\n",
    "The `pandas.DataFrame()` constructor is a versatile tool for creating DataFrames from various data structures. Understanding its parameters allows you to create DataFrames tailored to your specific needs. Here is a detailed explanation of each parameter:\n",
    "\n",
    "### Parameters in `pandas.DataFrame()`\n",
    "\n",
    "1. **`data`**: \n",
    "   - **Type**: Various (array-like, dict, or DataFrame)\n",
    "   - **Description**: The data to populate the DataFrame. This can be a list, dictionary, 2D array, another DataFrame, or other array-like structures.\n",
    "   - **Examples**:\n",
    "     - List of lists: `data=[[1, 2], [3, 4]]`\n",
    "     - Dictionary: `data={'col1': [1, 2], 'col2': [3, 4]}`\n",
    "     - Numpy array: `data=np.array([[1, 2], [3, 4]])`\n",
    "\n",
    "2. **`index`**:\n",
    "   - **Type**: array-like or Index (optional)\n",
    "   - **Description**: The labels for the rows. If not provided, it defaults to a range index starting from 0.\n",
    "   - **Example**:\n",
    "     - List: `index=['row1', 'row2']`\n",
    "\n",
    "3. **`columns`**:\n",
    "   - **Type**: array-like or Index (optional)\n",
    "   - **Description**: The labels for the columns. If not provided and `data` is a dictionary, it uses the keys of the dictionary.\n",
    "   - **Example**:\n",
    "     - List: `columns=['col1', 'col2']`\n",
    "\n",
    "4. **`dtype`**:\n",
    "   - **Type**: data type (optional)\n",
    "   - **Description**: The desired data type for the DataFrame’s elements. If not specified, data types are inferred.\n",
    "   - **Example**:\n",
    "     - `dtype=float`\n",
    "\n",
    "5. **`copy`**:\n",
    "   - **Type**: bool (default: False)\n",
    "   - **Description**: If `True`, the data is copied. If `False` and `data` is already a DataFrame, the original data is used without making a copy.\n",
    "   - **Example**:\n",
    "     - `copy=True`\n",
    "\n",
    "### Examples of Usage\n",
    "  \n",
    "1. **Creating a DataFrame from a Dictionary**:\n",
    "```\n",
    "    import pandas as pd\n",
    "\n",
    "   data = {\n",
    "       'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "       'Age': [25, 30, 35],\n",
    "       'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "   }\n",
    "   df = pd.DataFrame(data)\n",
    "   print(df)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "2. **Creating a DataFrame with a Custom Index**:\n",
    "   ```   \n",
    "   df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "   print(df)\n",
    "   ```\n",
    "\n",
    "3. **Creating a DataFrame with Specified Column Names**:\n",
    "\n",
    "   ```   \n",
    "   data = [[25, 'New York'], [30, 'Los Angeles'], [35, 'Chicago']]\n",
    "   df = pd.DataFrame(data, columns=['Age', 'City'])\n",
    "   print(df)\n",
    "   ```\n",
    "\n",
    "4. **Creating a DataFrame from a Numpy Array**:\n",
    "   ```   \n",
    "   import numpy as np\n",
    "\n",
    "   data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "   df = pd.DataFrame(data, columns=['A', 'B'], index=['row1', 'row2', 'row3'])\n",
    "   print(df)\n",
    "   ```\n",
    "\n",
    "5. **Specifying Data Types**:\n",
    "   ```   \n",
    "   data = {\n",
    "       'A': [1, 2, 3],\n",
    "       'B': [4.5, 5.5, 6.5]\n",
    "   }\n",
    "   df = pd.DataFrame(data, dtype=float)\n",
    "   print(df)\n",
    "   print(df.dtypes)\n",
    "   ```\n",
    "\n",
    "6. **Copying Data**:\n",
    "   ```  \n",
    "   original_data = {\n",
    "       'A': [1, 2, 3],\n",
    "       'B': [4, 5, 6]\n",
    "   }\n",
    "   df_original = pd.DataFrame(original_data)\n",
    "   df_copy = pd.DataFrame(df_original, copy=True)\n",
    "   df_original.loc[0, 'A'] = 99  # This will not affect df_copy\n",
    "   print(\"Original DataFrame:\\n\", df_original)\n",
    "   print(\"Copied DataFrame:\\n\", df_copy)\n",
    "   ```\n",
    "\n",
    "By understanding these parameters, you can effectively create and manipulate DataFrames to suit your specific data analysis needs. This flexibility makes Pandas a powerful tool for data manipulation and analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The df.iloc indexer in Pandas \n",
    "is used for selecting rows and columns from a DataFrame by their integer positions (i.e., purely integer-location based indexing). \n",
    "\n",
    "This method is useful when you need to select data by the position of rows and columns, rather than their labels.\n",
    "\n",
    "Here’s a detailed explanation of how df.iloc works, along with examples:\n",
    "\n",
    "Basic Syntax: **df.iloc[row_index, column_index]**\n",
    "row_index: The position(s) of the row(s) to select.\n",
    "column_index: The position(s) of the column(s) to select.\n",
    "\n",
    "Both row_index and column_index can be a single integer, a list of integers, or a slice.\n",
    "\n",
    "Examples and Use Cases\n",
    "1. Selecting a Single Row\n",
    "To select a single row by its integer position:\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Select the first row (index 0)\n",
    "row = df.iloc[0]\n",
    "print(row)\n",
    "\n",
    "2. Selecting Multiple Rows\n",
    "To select multiple rows by their integer positions:\n",
    "# Select the first and second rows (indices 0 and 1)\n",
    "rows = df.iloc[[0, 1]]\n",
    "print(rows)\n",
    "\n",
    "3. Selecting a Range of Rows\n",
    "To select a range of rows using slicing:\n",
    "# Select rows from index 0 to 1 (inclusive)\n",
    "rows = df.iloc[0:2]\n",
    "print(rows)\n",
    "\n",
    "4. Selecting a Single Column\n",
    "To select a single column by its integer position:\n",
    "# Select the first column (index 0)\n",
    "column = df.iloc[:, 0]\n",
    "print(column)\n",
    "\n",
    "5. Selecting Multiple Columns\n",
    "To select multiple columns by their integer positions:\n",
    "# Select the first and third columns (indices 0 and 2)\n",
    "columns = df.iloc[:, [0, 2]]\n",
    "print(columns)\n",
    "\n",
    "6. Selecting Specific Rows and Columns\n",
    "To select specific rows and columns by their integer positions:\n",
    "# Select the first row and the first and third columns\n",
    "selection = df.iloc[0, [0, 2]]\n",
    "print(selection)\n",
    "\n",
    "1. Using Slicing for Rows and Columns\n",
    "To select a range of rows and columns using slicing:\n",
    "# Select rows from index 0 to 1 and columns from index 0 to 2 (not inclusive)\n",
    "selection = df.iloc[0:2, 0:2]\n",
    "print(selection)\n",
    "\n",
    "## Key Points\n",
    "Zero-Based Indexing: df.iloc uses zero-based indexing, which means the first element is at position 0.\n",
    "Integer-Based: It strictly uses integer positions for selection.\n",
    "Slices and Lists: You can use slices (e.g., 0:2) and lists (e.g., [0, 2]) to specify multiple rows or columns.\n",
    "Read-Only Views: The views returned by df.iloc are read-only unless explicitly modified.\n",
    "Practical Applications\n",
    "Subset Selection: Useful for selecting a specific subset of data for analysis.\n",
    "Data Cleaning: Helpful in selecting and modifying specific parts of the data during the cleaning process.\n",
    "Testing and Debugging: Allows precise control over which rows and columns to access, making it easier to isolate and test specific parts of the data.\n",
    "By using df.iloc, you can efficiently and flexibly access and manipulate data in a Pandas DataFrame based on their integer positions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export a dataframe to a csv?\n",
    "to_csv() method of the DataFrame object. \n",
    "\n",
    "df.to_csv('filename.csv', index=True)\n",
    "Parameters\n",
    "'filename.csv': The name of the CSV file you want to create. You can include a path if you want to save it to a specific directory (e.g., 'path/to/filename.csv').\n",
    "index=True: By default, the index parameter is set to True, meaning that the row indices (index labels) of the DataFrame will be written to the CSV file. **If you don't want to include the index in the CSV file, set this parameter to False**.\n",
    "\n",
    "\n",
    "Example\n",
    "Let's say you have a DataFrame df and you want to export it to a CSV file named output.csv:\n",
    "\n",
    "import pandas as pd\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exporting DataFrame to CSV\n",
    "df.to_csv('output.csv', index=False)\n",
    "In this example:\n",
    "\n",
    "The DataFrame df is exported to a file named output.csv.\n",
    "The index=False parameter ensures that the row indices are not included in the CSV file.\n",
    "Additional Parameters\n",
    "The to_csv() method has several additional parameters that you can use to customize the output:\n",
    "\n",
    "sep: Specifies the delimiter (default is ',' for comma).\n",
    "df.to_csv('output.csv', sep=';')\n",
    "This example uses a semicolon as the delimiter instead of a comma.\n",
    "\n",
    "header: Specifies whether to write the column names (default is True).\n",
    "df.to_csv('output.csv', header=False)\n",
    "This example excludes the column names from the CSV file.\n",
    "\n",
    "columns: Specifies a list of columns to write.\n",
    "df.to_csv('output.csv', columns=['Name', 'City'])\n",
    "This example writes only the 'Name' and 'City' columns to the CSV file.\n",
    "\n",
    "mode: Specifies the file mode (default is 'w' for write).\n",
    "df.to_csv('output.csv', mode='a')\n",
    "This example appends the DataFrame to the existing CSV file.\n",
    "\n",
    "na_rep: String representation of missing values.\n",
    "df.to_csv('output.csv', na_rep='NA')\n",
    "This example represents missing values as 'NA' in the CSV file.\n",
    "\n",
    "\n",
    "Here’s an example using several parameters:\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exporting DataFrame to CSV with multiple parameters\n",
    "df.to_csv('output.csv', index=False, sep=';', header=True, columns=['Name', 'Age'], na_rep='NA')\n",
    "This example exports the 'Name' and 'Age' columns to output.csv, uses a semicolon as the delimiter, includes the column names, does not include the index, and represents missing values as 'NA'.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common DataFrame Attributes\n",
    "df.index\n",
    "Description: Provides the index (row labels) of the DataFrame.\n",
    "RangeIndex(start=0, stop=3, step=1)\n",
    "\n",
    "df.columns\n",
    "Description: Returns the column labels of the DataFrame.\n",
    "\n",
    "df.dtypes\n",
    "Description: Provides the data types of each column.\n",
    "\n",
    "df.shape\n",
    "Description: Returns a tuple representing the dimensionality of the DataFrame (number of rows and columns).\n",
    "\n",
    "df.size\n",
    "Description: Returns the number of elements in the DataFrame (rows × columns).\n",
    "\n",
    "df.values\n",
    "Description: Returns the DataFrame's data as a NumPy array.\n",
    "\n",
    "df.head() *Technically this is a method\n",
    "Description: Returns the first n rows of the DataFrame (default is 5).\n",
    "\n",
    "df.tail() *Technically this is a method\n",
    "Description: Returns the last n rows of the DataFrame (default is 5).\n",
    "\n",
    "df.T\n",
    "Description: Transposes the DataFrame (switches rows and columns).\n",
    "\n",
    "df.empty\n",
    "Description: Returns True if the DataFrame is empty; otherwise, False.\n",
    "\n",
    "df.ndim\n",
    "Description: Returns the number of dimensions of the DataFrame (always 2 for DataFrames).\n",
    "\n",
    "df.memory_usage()\n",
    "Description: Returns the memory usage of each column in bytes.\n",
    "\n",
    "## Using all of them together!\n",
    "Here’s an example showcasing these attributes with a DataFrame:\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying various attributes\n",
    "print(\"Index:\", df.index)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Data Types:\", df.dtypes)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Size:\", df.size)\n",
    "print(\"Values:\\n\", df.values)\n",
    "print(\"Head:\\n\", df.head())\n",
    "print(\"Tail:\\n\", df.tail())\n",
    "print(\"Transpose:\\n\", df.T)\n",
    "print(\"Is Empty:\", df.empty)\n",
    "print(\"Number of Dimensions:\", df.ndim)\n",
    "print(\"Memory Usage:\\n\", df.memory_usage())\n",
    "These attributes provide a comprehensive overview of the structure and content of a DataFrame, making them essential tools for data analysis and manipulation in Pandas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common DataFrame Methods\n",
    "df.head(n=5)\n",
    "Description: Returns the first n rows of the DataFrame.\n",
    "\n",
    "df.tail(n=5)\n",
    "Description: Returns the last n rows of the DataFrame.\n",
    "\n",
    "df.info()\n",
    "Description: Provides a concise summary of the DataFrame, including the index dtype, column dtypes, non-null values, and memory usage.\n",
    "\n",
    "df.describe()\n",
    "Description: Generates descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution, excluding NaN values.\n",
    "\n",
    "df.isna()\n",
    "Description: Detects missing values, returning a DataFrame of the same shape, indicating where values are NaN.\n",
    "\n",
    "df.fillna(value)\n",
    "Description: Fills missing values with a specified value.\n",
    "\n",
    "df.dropna()\n",
    "Description: Removes missing values.\n",
    "\n",
    "df.drop(columns)\n",
    "Description: Drops specified labels from columns.\n",
    "df.drop(columns=['Age'])\n",
    "\n",
    "df.rename(columns)\n",
    "Description: Renames labels (columns).\n",
    "df.rename(columns={'Name': 'First Name'})\n",
    "\n",
    "df.sort_values(by)\n",
    "Description: Sorts by the values along either axis.\n",
    "df.sort_values(by='Age')\n",
    "\n",
    "df.groupby(by)\n",
    "Description: Groups DataFrame using a mapper or by a Series of columns.\n",
    "df.groupby('City').mean()\n",
    "\n",
    "df.merge(right, on)\n",
    "Description: Merges DataFrame or named Series objects with a database-style join.\n",
    "df1.merge(df2, on='key')\n",
    "\n",
    "df.concat([dfs])\n",
    "Description: Concatenates pandas objects along a particular axis with optional set logic along the other axes.\n",
    "pd.concat([df1, df2])\n",
    "\n",
    "df.apply(func)\n",
    "Description: Applies a function along an axis of the DataFrame.\n",
    "df.apply(np.sqrt)\n",
    "\n",
    "df.agg(func)\n",
    "Description: Aggregates using one or more operations over the specified axis.\n",
    "df.agg(['sum', 'min'])\n",
    "\n",
    "df.pivot(index, columns, values)\n",
    "Description: Reshapes data (produce a “pivot” table) based on column values.\n",
    "df.pivot(index='Date', columns='City', values='Temperature')\\\n",
    "\n",
    "df.pivot_table(values, index, columns, aggfunc)\n",
    "Description: Creates a pivot table as a DataFrame.\n",
    "df.pivot_table(values='Sales', index='Date', columns='Store', aggfunc='sum')\n",
    "\n",
    "df.melt(id_vars, value_vars)\n",
    "Description: Unpivots a DataFrame from wide format to long format.\n",
    "df.melt(id_vars=['City'], value_vars=['Sales'])\n",
    "\n",
    "df.to_csv(filename)\n",
    "Description: Writes the DataFrame to a CSV file.\n",
    "df.to_csv('data.csv')\n",
    "\n",
    "df.to_excel(filename)\n",
    "Description: Writes the DataFrame to an Excel file.\n",
    "df.to_excel('data.xlsx')\n",
    "\n",
    "df.to_json(filename)\n",
    "Description: Writes the DataFrame to a JSON file.\n",
    "df.to_json('data.json')\n",
    "\n",
    "\n",
    "\n",
    "Here’s an example showcasing some of these methods with a DataFrame:\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Using some common methods\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isna())\n",
    "df.fillna(0)\n",
    "df.drop(columns=['Age'])\n",
    "df.rename(columns={'Name': 'First Name'})\n",
    "df.sort_values(by='Age')\n",
    "grouped_df = df.groupby('City').mean()\n",
    "**These methods provide powerful tools for data manipulation, cleaning, aggregation, and export, making Pandas an essential library for data analysis in Python.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics are used to summarize and describe the main features of a dataset including statistics. \n",
    "In the context of the Pandas library, descriptive statistics help provide a quick overview of the **distribution**, **central tendency**, and **variability** of the data within a DataFrame. Pandas provides several methods to compute descriptive statistics, which can give insights into the structure and characteristics of the data.\n",
    "\n",
    "## Key Concepts in Descriptive Statistics\n",
    "## Central Tendency: Measures that describe the center of a dataset.\n",
    "\n",
    "Mean: The average value of the data.\n",
    "Median: The middle value of the data when it is ordered.\n",
    "Mode: The most frequently occurring value in the data.\n",
    "Dispersion: Measures that describe the spread of the data.\n",
    "\n",
    "## Standard Deviation: A measure of the amount of variation or dispersion in the data.\n",
    "Variance: The average of the squared differences from the mean.\n",
    "Range: The difference between the maximum and minimum values.\n",
    "Interquartile Range (IQR): The range of the middle 50% of the data.\n",
    "Distribution: Measures that describe the shape of the data distribution.\n",
    "\n",
    "## Skewness: A measure of the asymmetry of the data distribution.\n",
    "Kurtosis: A measure of the \"tailedness\" of the data distribution.\n",
    "\n",
    "\n",
    "## Using Pandas for Descriptive Statistics\n",
    "Pandas provides several methods to calculate descriptive statistics easily. Here are some of the most commonly used methods:\n",
    "\n",
    "1. describe()\n",
    "The describe() method generates a summary of statistics for numeric columns in a DataFrame.\n",
    "\n",
    "2. Individual Descriptive Statistics Methods\n",
    "Mean: df.mean()\n",
    "Median: df.median()\n",
    "Mode: df.mode()\n",
    "Standard Deviation: df.std()\n",
    "Variance: df.var()\n",
    "Skewness: df.skew()\n",
    "Kurtosis: df.kurt()\n",
    "print(df.kurt())\n",
    "\n",
    "Example of all of them:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45],\n",
    "    'Salary': [50000, 60000, 70000, 80000, 90000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mean\n",
    "print(\"Mean:\\n\", df.mean())\n",
    "\n",
    "# Median\n",
    "print(\"Median:\\n\", df.median())\n",
    "\n",
    "# Mode\n",
    "print(\"Mode:\\n\", df.mode())\n",
    "\n",
    "# Standard Deviation\n",
    "print(\"Standard Deviation:\\n\", df.std())\n",
    "\n",
    "# Variance\n",
    "print(\"Variance:\\n\", df.var())\n",
    "\n",
    "# Skewness\n",
    "print(\"Skewness:\\n\", df.skew())\n",
    "\n",
    "# Kurtosis\n",
    "print(\"Kurtosis:\\n\", df.kurt())\n",
    "\n",
    "Practical Applications\n",
    "Exploratory Data Analysis (EDA): Descriptive statistics are fundamental in EDA to understand the distribution and key properties of the data before performing further analysis or modeling.\n",
    "Data Cleaning: Identifying outliers, missing values, and data anomalies.\n",
    "Business Reporting: Summarizing data trends and key performance indicators (KPIs).\n",
    "Statistical Analysis: Providing the foundation for more complex statistical analysis and hypothesis testing.\n",
    "By using these methods, Pandas allows users to quickly and efficiently gain insights into their data, making it a powerful tool for data analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Aggregate Functions\n",
    "\n",
    "Aggregate functions in Pandas are used to perform operations on data that result in a single value summarizing the information from a dataset or a subset of it. These functions are commonly used in conjunction with grouping operations (groupby) to perform analysis on different segments of data.\n",
    "\n",
    "\n",
    "sum()\n",
    "Description: Calculates the sum of values for each column.\n",
    "\n",
    "mean()\n",
    "Description: Calculates the mean (average) of values for each column.\n",
    "\n",
    "median()\n",
    "Description: Calculates the median value for each column.\n",
    "\n",
    "min()\n",
    "Description: Finds the minimum value for each column.\n",
    "\n",
    "max()\n",
    "Description: Finds the maximum value for each column.\n",
    "\n",
    "count()\n",
    "Description: Counts the number of non-null values for each column.\n",
    "\n",
    "std()\n",
    "Description: Calculates the standard deviation of values for each column.\n",
    "\n",
    "var()\n",
    "Description: Calculates the variance of values for each column.\n",
    "\n",
    "prod()\n",
    "Description: Calculates the product of values for each column.\n",
    "\n",
    "first()\n",
    "Description: Returns rows from the start up to the given time offset.\n",
    "df.first(offset): Specifically designed for **time series data** with a datetime index. Takes a time offset string (like '2D') indicating the period to select.\n",
    "\n",
    "last()\n",
    "\n",
    "agg() or aggregate()\n",
    "Description: Applies one or more operations over the specified axis.\n",
    "df.agg(['sum', 'mean', 'std'])\n",
    "\n",
    "## Using Aggregate Functions with groupby\n",
    "These aggregate functions are often used with the groupby method to perform aggregation on groups of data. Here’s how to use these functions with groupby:\n",
    "\n",
    "Example DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Department': ['Sales', 'Sales', 'HR', 'HR', 'IT', 'IT'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'Salary': [70000, 80000, 60000, 65000, 90000, 95000],\n",
    "    'Years': [5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "Aggregating with groupby\n",
    "Sum of Salaries by Department\n",
    "df.groupby('Department')['Salary'].sum()\n",
    "Mean Salary and Years by Department\n",
    "df.groupby('Department').agg({'Salary': 'mean', 'Years': 'mean'})\n",
    "Count of Employees by Department\n",
    "df.groupby('Department')['Employee'].count()\n",
    "Multiple Aggregations\n",
    "df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'sum', 'max'],\n",
    "    'Years': ['mean', 'std']\n",
    "})\n",
    "Example Output\n",
    "Sum of Salaries by Department\n",
    "print(df.groupby('Department')['Salary'].sum())\n",
    "\n",
    "Mean Salary and Years by Department\n",
    "print(df.groupby('Department').agg({'Salary': 'mean', 'Years': 'mean'}))\n",
    "\n",
    "Count of Employees by Department\n",
    "print(df.groupby('Department')['Employee'].count())\n",
    "\n",
    "Multiple Aggregations\n",
    "print(df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'sum', 'max'],\n",
    "    'Years': ['mean', 'std']\n",
    "}))\n",
    "\n",
    "By using these aggregate functions, you can effectively summarize and analyze data in a Pandas DataFrame, providing valuable insights into the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a field's (column's) datatype using the astype() method.\n",
    "This method allows you to **explicitly** change the data type of a column to the desired type. \n",
    "\n",
    "Basic Syntax\n",
    "df['column_name'] = df['column_name'].astype(new_type)\n",
    "Common Data Types\n",
    "int: Integer\n",
    "float: Floating-point number\n",
    "str: String\n",
    "bool: Boolean\n",
    "datetime: Datetime\n",
    "Examples\n",
    "Example DataFrame\n",
    "Let's start with a sample DataFrame:\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'A': ['1', '2', '3', '4'],\n",
    "    'B': [1.5, 2.5, 3.5, 4.5],\n",
    "    'C': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "Converting a Column to Integer\n",
    "Convert column 'A' from string to integer:\n",
    "df['A'] = df['A'].astype(int)\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "\n",
    "Using the astype() method and other conversion functions in Pandas allows you to effectively manage and manipulate data types within your DataFrame, ensuring that your data is in the correct format for analysis and computation.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting categorical variables into dummy variables \n",
    "(also known as one-hot encoding) is a common preprocessing step in data analysis and machine learning. \n",
    "Why Convert Categorical Variables into Dummy Variables\n",
    "Machine Learning Algorithms: Many machine learning algorithms require numerical input and cannot directly work with categorical data.\n",
    "\n",
    "## Why Convert Categorical Variables into Dummy Variables\n",
    "Many algorithms, such as linear regression, logistic regression, and most tree-based methods, require numerical input and cannot directly handle categorical data.\n",
    "Prevent Ordinal Relationships: One-hot encoding avoids introducing unintended ordinal relationships between categorical values. For instance, labeling categories as 0, 1, 2 could misleadingly imply an order or hierarchy, which may not exist.\n",
    "Simplicity and Efficiency: Dummy variables provide a straightforward and efficient way to represent categorical data numerically, making it easier for algorithms to process and interpret.\n",
    "\n",
    "## How to Convert Categorical Variables to Dummy Variables\n",
    "Pandas provides a convenient method called `get_dummies()` to perform one-hot encoding.\n",
    "\n",
    "Example DataFrame\n",
    "Let's consider a simple DataFrame with a categorical variable:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red'],\n",
    "    'Size': ['S', 'M', 'L', 'M', 'S'],\n",
    "    'Price': [10, 20, 30, 20, 10]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "Converting Categorical Variables\n",
    "Use the pd.get_dummies() method to convert the categorical variables:\n",
    "\n",
    "## One-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Color', 'Size'])\n",
    "print(df_encoded)\n",
    "\n",
    "In this example:\n",
    "\n",
    "The Color column with categories 'Red', 'Blue', 'Green' is converted into three binary columns: Color_Blue, Color_Green, and Color_Red.\n",
    "The Size column with categories 'S', 'M', 'L' is converted into three binary columns: Size_S, Size_M, and Size_L.\n",
    "\n",
    "\n",
    "Detailed Explanation\n",
    "Importing the Library:\n",
    "\n",
    "import pandas as pd\n",
    "Creating the DataFrame:\n",
    "The DataFrame df contains two categorical variables (Color and Size) and one numerical variable (Price).\n",
    "\n",
    "One-Hot Encoding:\n",
    "df_encoded = pd.get_dummies(df, columns=['Color', 'Size'])\n",
    "The pd.get_dummies() function converts the specified categorical columns into a set of binary columns.\n",
    "The columns parameter specifies which columns to encode. If omitted, all object-type columns are converted by default.\n",
    "Practical Considerations\n",
    "Avoiding Multicollinearity: In regression models, one-hot encoding can introduce multicollinearity. This can be avoided by dropping one of the dummy columns for each categorical feature using the drop_first=True parameter:\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['Color', 'Size'], drop_first=True)\n",
    "Handling Many Categories: If a categorical variable has many unique values, one-hot encoding can produce a large number of columns, which might be inefficient. In such cases, techniques like target encoding or feature hashing might be considered.\n",
    "By converting categorical variables into dummy variables, you prepare your data for machine learning models, ensuring that categorical information is appropriately represented numerically without introducing spurious ordinal relationships.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "Exploratory Data Analysis (EDA) is a crucial step in the data analysis process where you summarize the main characteristics of a dataset, often using visual methods. Performing EDA helps you **understand the structure, patterns, and relationships** within your data. \n",
    "\n",
    "## Understand Data Distributions:\n",
    "\n",
    "Identify Patterns: Helps in recognizing patterns, trends, and anomalies in the data.\n",
    "Detect Outliers: Reveals outliers or unusual observations that may affect the analysis or model performance.\n",
    "Determine the Spread: Assesses the spread and central tendency (mean, median) of the data.\n",
    "\n",
    "\n",
    "## Inform Data Cleaning:\n",
    "\n",
    "Handle Missing Values: Identifies and determines strategies for handling missing data.\n",
    "Correct Errors: Detects data entry errors or inconsistencies that need correction.\n",
    "\n",
    "\n",
    "## Guide Feature Selection:\n",
    "\n",
    "Feature Importance: Helps in understanding which features are important and how they relate to the target variable.\n",
    "Remove Redundancies: Identifies and removes redundant or irrelevant features.\n",
    "\n",
    "\n",
    "## Select Appropriate Models:\n",
    "\n",
    "Model Assumptions: Helps in checking assumptions required for various statistical models, such as normality, linearity, and homoscedasticity.\n",
    "Transformation Needs: Indicates if data transformation (e.g., log transformation) is necessary to meet model assumptions.\n",
    "\n",
    "\n",
    "## How to Perform Exploratory Data Analysis\n",
    "1. Summary Statistics\n",
    "describe(): Provides a summary of the central tendency, dispersion, and shape of a dataset’s distribution.\n",
    "2. Data Visualization\n",
    "   **NOTE: THIS IS NOT BUILT INTO PANDAS!!!!!**\n",
    "   **THIS REQUIRES MATPLOTLIB!!**\n",
    "Visualization is key in EDA to get a better sense of the data distribution and relationships.\n",
    "\n",
    "Histograms: Show the frequency distribution of a single variable.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Age'].hist(bins=5)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Age')\n",
    "plt.show()\n",
    "Box Plots: Show the distribution of data based on a five-number summary (minimum, first quartile, median, third quartile, and maximum).\n",
    "df.boxplot(column='Salary')\n",
    "plt.title('Boxplot of Salary')\n",
    "plt.show()\n",
    "Scatter Plots: Show the relationship between two variables.\n",
    "df.plot.scatter(x='Age', y='Salary')\n",
    "plt.title('Scatter Plot of Age vs Salary')\n",
    "plt.show()\n",
    "Pair Plots: Show pairwise relationships in a dataset.\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "1. Checking for Missing Values\n",
    "isna() and sum(): Identify missing values in the dataset.\n",
    "\n",
    "print(df.isna().sum())\n",
    "1. Correlation Matrix\n",
    "corr(): Computes the correlation matrix to understand the relationship between variables.\n",
    "print(df.corr())\n",
    "Heatmap: Visual representation of the correlation matrix.\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "Example of EDA\n",
    "Here’s an example that combines several EDA techniques:\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60],\n",
    "    'Salary': [50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000],\n",
    "    'Gender': ['F', 'M', 'M', 'F', 'F', 'M', 'M', 'F']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Summary Statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Missing Values\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Histograms\n",
    "df['Age'].hist(bins=5)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Age')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "df.boxplot(column='Salary')\n",
    "plt.title('Boxplot of Salary')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "df.plot.scatter(x='Age', y='Salary')\n",
    "plt.title('Scatter Plot of Age vs Salary')\n",
    "plt.show()\n",
    "\n",
    "# Pair Plot\n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix and Heatmap\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "By performing EDA, you gain a deeper understanding of your dataset, which helps in making informed decisions about data preprocessing, feature selection, and model choice. This understanding is crucial for developing accurate and reliable predictive models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
